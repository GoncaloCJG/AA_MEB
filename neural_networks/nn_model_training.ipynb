{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e742ecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's build a convolutional neural network for the 3-label classification ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d275bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 14:48:52.433108: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-14 14:48:53.355403: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ricardo/Documents/MEB/AA/aaenv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-01-14 14:48:53.355499: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ricardo/Documents/MEB/AA/aaenv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-01-14 14:48:53.355508: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Activation, Conv2D, Dense, Flatten, MaxPooling2D, BatchNormalization, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35e50b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>green_iqr</th>\n",
       "      <th>blue_iqr</th>\n",
       "      <th>original_firstorder_Entropy</th>\n",
       "      <th>original_glcm_Autocorrelation</th>\n",
       "      <th>original_glcm_Imc1</th>\n",
       "      <th>original_glcm_Imc2</th>\n",
       "      <th>original_gldm_LargeDependenceEmphasis</th>\n",
       "      <th>original_gldm_LargeDependenceLowGrayLevelEmphasis</th>\n",
       "      <th>original_glrlm_LongRunLowGrayLevelEmphasis</th>\n",
       "      <th>original_glszm_ZoneEntropy</th>\n",
       "      <th>original_ngtdm_Complexity</th>\n",
       "      <th>original_ngtdm_Strength</th>\n",
       "      <th>melanoma</th>\n",
       "      <th>seborrheic_keratosis</th>\n",
       "      <th>neither</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0000001</td>\n",
       "      <td>58</td>\n",
       "      <td>40</td>\n",
       "      <td>1.163592</td>\n",
       "      <td>6.023905</td>\n",
       "      <td>-0.403236</td>\n",
       "      <td>0.770104</td>\n",
       "      <td>4.672684</td>\n",
       "      <td>0.974713</td>\n",
       "      <td>0.299423</td>\n",
       "      <td>2.777913</td>\n",
       "      <td>0.808480</td>\n",
       "      <td>0.124740</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0000002</td>\n",
       "      <td>52</td>\n",
       "      <td>67</td>\n",
       "      <td>0.112792</td>\n",
       "      <td>3.988779</td>\n",
       "      <td>-0.564990</td>\n",
       "      <td>0.250990</td>\n",
       "      <td>5.051852</td>\n",
       "      <td>1.278172</td>\n",
       "      <td>0.380191</td>\n",
       "      <td>1.932127</td>\n",
       "      <td>0.007574</td>\n",
       "      <td>0.941026</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0000004</td>\n",
       "      <td>44</td>\n",
       "      <td>55</td>\n",
       "      <td>2.589392</td>\n",
       "      <td>31.008519</td>\n",
       "      <td>-0.770726</td>\n",
       "      <td>0.988910</td>\n",
       "      <td>4.673329</td>\n",
       "      <td>0.806039</td>\n",
       "      <td>0.268533</td>\n",
       "      <td>4.275156</td>\n",
       "      <td>3.153283</td>\n",
       "      <td>2.213424</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0000006</td>\n",
       "      <td>76</td>\n",
       "      <td>101</td>\n",
       "      <td>0.440230</td>\n",
       "      <td>1.211871</td>\n",
       "      <td>-0.222705</td>\n",
       "      <td>0.401163</td>\n",
       "      <td>4.594168</td>\n",
       "      <td>4.418287</td>\n",
       "      <td>1.346867</td>\n",
       "      <td>2.115149</td>\n",
       "      <td>0.049819</td>\n",
       "      <td>0.046243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0000009</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>0.988476</td>\n",
       "      <td>2.683550</td>\n",
       "      <td>-0.541114</td>\n",
       "      <td>0.806245</td>\n",
       "      <td>4.652174</td>\n",
       "      <td>2.641480</td>\n",
       "      <td>0.819539</td>\n",
       "      <td>2.553233</td>\n",
       "      <td>0.065349</td>\n",
       "      <td>0.021467</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>ISIC_0015220</td>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "      <td>1.713805</td>\n",
       "      <td>6.160656</td>\n",
       "      <td>-0.803562</td>\n",
       "      <td>0.964020</td>\n",
       "      <td>7.478586</td>\n",
       "      <td>2.277177</td>\n",
       "      <td>5.152584</td>\n",
       "      <td>4.435975</td>\n",
       "      <td>0.271341</td>\n",
       "      <td>0.070004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>ISIC_0015233</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>1.192893</td>\n",
       "      <td>7.055527</td>\n",
       "      <td>-0.746103</td>\n",
       "      <td>0.909626</td>\n",
       "      <td>5.027475</td>\n",
       "      <td>0.864552</td>\n",
       "      <td>0.267658</td>\n",
       "      <td>3.028206</td>\n",
       "      <td>0.237932</td>\n",
       "      <td>0.042187</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>ISIC_0015260</td>\n",
       "      <td>51</td>\n",
       "      <td>34</td>\n",
       "      <td>1.184338</td>\n",
       "      <td>4.310333</td>\n",
       "      <td>-0.629008</td>\n",
       "      <td>0.887234</td>\n",
       "      <td>7.512658</td>\n",
       "      <td>2.805714</td>\n",
       "      <td>5.593992</td>\n",
       "      <td>4.190389</td>\n",
       "      <td>0.904079</td>\n",
       "      <td>0.132170</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>ISIC_0015284</td>\n",
       "      <td>76</td>\n",
       "      <td>85</td>\n",
       "      <td>2.421955</td>\n",
       "      <td>16.197648</td>\n",
       "      <td>-0.811300</td>\n",
       "      <td>0.988714</td>\n",
       "      <td>5.205730</td>\n",
       "      <td>0.730521</td>\n",
       "      <td>0.553786</td>\n",
       "      <td>4.160087</td>\n",
       "      <td>2.045905</td>\n",
       "      <td>0.333450</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>ISIC_0015295</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>1.644210</td>\n",
       "      <td>34.929123</td>\n",
       "      <td>-0.571392</td>\n",
       "      <td>0.915012</td>\n",
       "      <td>7.004708</td>\n",
       "      <td>0.224182</td>\n",
       "      <td>0.200214</td>\n",
       "      <td>4.794445</td>\n",
       "      <td>4.488607</td>\n",
       "      <td>0.110753</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1314 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          image_id  green_iqr  blue_iqr  original_firstorder_Entropy  \\\n",
       "0     ISIC_0000001         58        40                     1.163592   \n",
       "1     ISIC_0000002         52        67                     0.112792   \n",
       "2     ISIC_0000004         44        55                     2.589392   \n",
       "3     ISIC_0000006         76       101                     0.440230   \n",
       "4     ISIC_0000009         60        58                     0.988476   \n",
       "...            ...        ...       ...                          ...   \n",
       "1309  ISIC_0015220         47        51                     1.713805   \n",
       "1310  ISIC_0015233         73        59                     1.192893   \n",
       "1311  ISIC_0015260         51        34                     1.184338   \n",
       "1312  ISIC_0015284         76        85                     2.421955   \n",
       "1313  ISIC_0015295         39        36                     1.644210   \n",
       "\n",
       "      original_glcm_Autocorrelation  original_glcm_Imc1  original_glcm_Imc2  \\\n",
       "0                          6.023905           -0.403236            0.770104   \n",
       "1                          3.988779           -0.564990            0.250990   \n",
       "2                         31.008519           -0.770726            0.988910   \n",
       "3                          1.211871           -0.222705            0.401163   \n",
       "4                          2.683550           -0.541114            0.806245   \n",
       "...                             ...                 ...                 ...   \n",
       "1309                       6.160656           -0.803562            0.964020   \n",
       "1310                       7.055527           -0.746103            0.909626   \n",
       "1311                       4.310333           -0.629008            0.887234   \n",
       "1312                      16.197648           -0.811300            0.988714   \n",
       "1313                      34.929123           -0.571392            0.915012   \n",
       "\n",
       "      original_gldm_LargeDependenceEmphasis  \\\n",
       "0                                  4.672684   \n",
       "1                                  5.051852   \n",
       "2                                  4.673329   \n",
       "3                                  4.594168   \n",
       "4                                  4.652174   \n",
       "...                                     ...   \n",
       "1309                               7.478586   \n",
       "1310                               5.027475   \n",
       "1311                               7.512658   \n",
       "1312                               5.205730   \n",
       "1313                               7.004708   \n",
       "\n",
       "      original_gldm_LargeDependenceLowGrayLevelEmphasis  \\\n",
       "0                                              0.974713   \n",
       "1                                              1.278172   \n",
       "2                                              0.806039   \n",
       "3                                              4.418287   \n",
       "4                                              2.641480   \n",
       "...                                                 ...   \n",
       "1309                                           2.277177   \n",
       "1310                                           0.864552   \n",
       "1311                                           2.805714   \n",
       "1312                                           0.730521   \n",
       "1313                                           0.224182   \n",
       "\n",
       "      original_glrlm_LongRunLowGrayLevelEmphasis  original_glszm_ZoneEntropy  \\\n",
       "0                                       0.299423                    2.777913   \n",
       "1                                       0.380191                    1.932127   \n",
       "2                                       0.268533                    4.275156   \n",
       "3                                       1.346867                    2.115149   \n",
       "4                                       0.819539                    2.553233   \n",
       "...                                          ...                         ...   \n",
       "1309                                    5.152584                    4.435975   \n",
       "1310                                    0.267658                    3.028206   \n",
       "1311                                    5.593992                    4.190389   \n",
       "1312                                    0.553786                    4.160087   \n",
       "1313                                    0.200214                    4.794445   \n",
       "\n",
       "      original_ngtdm_Complexity  original_ngtdm_Strength  melanoma  \\\n",
       "0                      0.808480                 0.124740         0   \n",
       "1                      0.007574                 0.941026         1   \n",
       "2                      3.153283                 2.213424         1   \n",
       "3                      0.049819                 0.046243         0   \n",
       "4                      0.065349                 0.021467         0   \n",
       "...                         ...                      ...       ...   \n",
       "1309                   0.271341                 0.070004         0   \n",
       "1310                   0.237932                 0.042187         0   \n",
       "1311                   0.904079                 0.132170         0   \n",
       "1312                   2.045905                 0.333450         1   \n",
       "1313                   4.488607                 0.110753         0   \n",
       "\n",
       "      seborrheic_keratosis  neither  \n",
       "0                        0        1  \n",
       "1                        0        0  \n",
       "2                        0        0  \n",
       "3                        0        1  \n",
       "4                        0        1  \n",
       "...                    ...      ...  \n",
       "1309                     1        0  \n",
       "1310                     1        0  \n",
       "1311                     1        0  \n",
       "1312                     0        0  \n",
       "1313                     1        0  \n",
       "\n",
       "[1314 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load the 3-class dataset\n",
    "data = pd.read_csv('../fifty_neither_vs_mel_keratosis_features_targets.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80cab8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnostic column:\n",
    "## 0 - neither, 1 - melanoma, 2 - seborrheic keratosis, \n",
    "for i,u in enumerate(data['image_id']):\n",
    "    if data.loc[i,'melanoma'] == 0:\n",
    "        if data.loc[i,'seborrheic_keratosis'] == 1:\n",
    "            data.loc[i,'melanoma'] = 2\n",
    "    else:\n",
    "        continue      \n",
    "data.drop(columns=['seborrheic_keratosis', 'neither'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac5a9996",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.DataFrame(data[['image_id','melanoma']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a763e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>melanoma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0000001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0000002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0000004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0000006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0000009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>ISIC_0015220</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>ISIC_0015233</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>ISIC_0015260</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>ISIC_0015284</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>ISIC_0015295</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1314 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          image_id  melanoma\n",
       "0     ISIC_0000001         0\n",
       "1     ISIC_0000002         1\n",
       "2     ISIC_0000004         1\n",
       "3     ISIC_0000006         0\n",
       "4     ISIC_0000009         0\n",
       "...            ...       ...\n",
       "1309  ISIC_0015220         2\n",
       "1310  ISIC_0015233         2\n",
       "1311  ISIC_0015260         2\n",
       "1312  ISIC_0015284         1\n",
       "1313  ISIC_0015295         2\n",
       "\n",
       "[1314 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c655528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../segmented/SEGISIC_0015295.jpg\n",
      "(150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "## Get images array and add to DataFrame\n",
    "## image array shape (image, width, height, rgb)\n",
    "\n",
    "path = '../../segmented/SEG'\n",
    "X = []\n",
    "Y = []\n",
    "for i in targets['image_id']:\n",
    "    clear_output(wait=True)\n",
    "    print(path+i+'.jpg')\n",
    "    impath = path + i + '.jpg'\n",
    "    im = cv.imread(impath, -1)\n",
    "    im_rgb = cv.cvtColor(im, cv.COLOR_BGR2RGB)\n",
    "    # augment data through flipping and blurring\n",
    "    im_flipped_0 = cv.flip(im_rgb,0)\n",
    "\n",
    "    \n",
    "    print(np.shape(im_rgb))\n",
    "    X.append(im_rgb)\n",
    "    Y.append(targets[targets['image_id']==i]['melanoma'].item())\n",
    "    \n",
    "    X.append(im_flipped_0)\n",
    "    Y.append(targets[targets['image_id']==i]['melanoma'].item())\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59d1dcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2628, 150, 150, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47d848c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfa065e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1., 0., 0.] - neither, [0., 1., 0.] melanoma, [0., 0., 1.] keratosis\n",
    "Y = to_categorical(Y, num_classes=3)\n",
    "Y\n",
    "\n",
    "# normalize pixel values\n",
    "X = (X-127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00620a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 146, 146, 32)      2432      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 146, 146, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 73, 73, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 69, 69, 50)        40050     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 69, 69, 50)       200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 69, 69, 50)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 65, 65, 50)        62550     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 65, 65, 50)       200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 65, 65, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 50)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 51200)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                1638432   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,744,091\n",
      "Trainable params: 1,743,827\n",
      "Non-trainable params: 264\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 14:48:58.618577: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ricardo/Documents/MEB/AA/aaenv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-01-14 14:48:58.618619: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-01-14 14:48:58.618981: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Neural network structure\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(50, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Conv2D(50, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc6c5118",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ce4fb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo/Documents/MEB/AA/aaenv/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b58503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2198b8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "237/237 [==============================] - 164s 688ms/step - loss: 6.5002 - acc: 0.4867 - val_loss: 211.2310 - val_acc: 0.4563\n",
      "Epoch 2/5\n",
      "237/237 [==============================] - 163s 686ms/step - loss: 1.0123 - acc: 0.5252 - val_loss: 1056.0369 - val_acc: 0.2471\n",
      "Epoch 3/5\n",
      "237/237 [==============================] - 163s 689ms/step - loss: 1.0123 - acc: 0.5239 - val_loss: 490.2979 - val_acc: 0.3954\n",
      "Epoch 4/5\n",
      "237/237 [==============================] - 164s 694ms/step - loss: 1.0107 - acc: 0.5243 - val_loss: 493.5303 - val_acc: 0.4183\n",
      "Epoch 5/5\n",
      "180/237 [=====================>........] - ETA: 39s - loss: 1.0222 - acc: 0.5133"
     ]
    }
   ],
   "source": [
    "h = model.fit(X_train, y_train, batch_size=10, epochs=5, validation_data=(X_test, y_test))\n",
    "\n",
    "plt.plot(h.history['acc'])\n",
    "plt.plot(h.history['val_acc'])\n",
    "plt.title(\"Train and test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6d0ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaenv",
   "language": "python",
   "name": "aaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
