{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e15c5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This scripts serves as the extractor for all features used in this project\n",
    "## it will iterate through each image in the dataset and extract features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17fcec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from radiomics import featureextractor\n",
    "from IPython.display import clear_output\n",
    "from iteration_utilities import flatten, deepflatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31459186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>age_approximate</th>\n",
       "      <th>sex</th>\n",
       "      <th>melanoma</th>\n",
       "      <th>seborrheic_keratosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0000000</td>\n",
       "      <td>55</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0000001</td>\n",
       "      <td>30</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0000002</td>\n",
       "      <td>60</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0000003</td>\n",
       "      <td>30</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0000004</td>\n",
       "      <td>80</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id age_approximate     sex  melanoma  seborrheic_keratosis\n",
       "0  ISIC_0000000              55  female       0.0                   0.0\n",
       "1  ISIC_0000001              30  female       0.0                   0.0\n",
       "2  ISIC_0000002              60  female       1.0                   0.0\n",
       "3  ISIC_0000003              30    male       0.0                   0.0\n",
       "4  ISIC_0000004              80    male       1.0                   0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data csv. The original file contains the images names and patient data\n",
    "training_data_csv = pd.read_csv('../merged_training_data.csv')\n",
    "training_data_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a455607",
   "metadata": {},
   "outputs": [],
   "source": [
    "## image and mask loading\n",
    "\n",
    "def img_mask_load(img_name_load):\n",
    "    \n",
    "    ''' \n",
    "    \n",
    "    Function that takes the image name \n",
    "    from the Dataframe, searches this name in the image directory\n",
    "    and loads it, along with the corresponding mask. Also, applies\n",
    "    the mask to perform the segmentation along with histogram normalization\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    im_path = '../../ISIC-2017_Training_Data/' ## CHANGE THIS VARIABLE WITH THE PATH WHERE YOU HAVE THE IMAGES\n",
    "    mask_path = '../../ISIC-2017_Training_Part1_GroundTruth/' ## CHANGE THIS VARIABLE WITH THE PATH WHERE THE MAKS ARE\n",
    "    img = cv.imread(im_path + img_name_load + '.jpg',-1)\n",
    "    img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    mask = cv.imread(mask_path + img_name_load + '_segmentation.png', -1)\n",
    "    output_array = np.zeros((img.shape[0],img.shape[1])) # Array to store normalized image\n",
    "    img_segmented = cv.normalize(cv.bitwise_and(img_rgb, img_rgb, mask=mask),  output_array, 0, 255, cv.NORM_MINMAX)\n",
    "    \n",
    "    # return the segmented image for color channel features, and bgr image and mask for pyradiomics\n",
    "    return img_segmented, img, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0386dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for RGB features extraction\n",
    "\n",
    "def features_rgb(img_name):\n",
    "    '''\n",
    "    \n",
    "    This function extracts the following rgb features:\n",
    "    color channel mode, median and interquartile distance\n",
    "    A normalized segmented RGB image is the only argument.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # segment the image using the segmentation function\n",
    "    segmented, _, _, = img_mask_load(img_name)\n",
    "    \n",
    "    # Tuple with each color channel\n",
    "    color = ('r','g','b')\n",
    "    \n",
    "    \n",
    "    #  Declare list to store the most repeated pixel intensity in each channel\n",
    "    mode_color_channel = []\n",
    "    bp = []\n",
    "    medians = []\n",
    "    iqrs = []\n",
    "    \n",
    "\n",
    "    # Iterate through each color channel and obtain histogram\n",
    "    for i,col in enumerate(color):   \n",
    "        histr = cv.calcHist([segmented],[i],None,[256],[1,256]) # the range should be [1,256] to exclude black background    \n",
    "        mode_color_channel.append(list(histr.flatten()).index(max(histr.flatten()))) # append mode to mode list\n",
    "        bp.append(segmented[:,:,i].flatten()[segmented[:,:,i].flatten().nonzero()])\n",
    "        \n",
    "    for i in range(len(bp)):\n",
    "        medians.append(round(np.median(bp[i]))) # get median\n",
    "        q3, q1 = np.percentile(bp[i], [75,25]) # get 3rd quartile and 1st quartile\n",
    "        iqr = round(q3 - q1) # calculate quartile diference\n",
    "        iqrs.append(iqr) # append to interquartile range array\n",
    "                    \n",
    "    return mode_color_channel, medians, iqrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0572dbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for Radiomics features extraction\n",
    "\n",
    "def features_radiomics(img_name):\n",
    "    '''\n",
    "    This function extracts the features described in pyradiomics:\n",
    "    https://pyradiomics.readthedocs.io/en/latest/features.html\n",
    "    A normalized RGB image and mask tuple is the only argument.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Load image path\n",
    "    _, img, mask = img_mask_load(img_name) # segment the image using img_mask_load function. we don't need the segmented image so we _ it\n",
    "    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY) # convert image to grayscale\n",
    "    \n",
    "    im, label = '../pyradiomicsdir/img_gray_1.jpg' , '../pyradiomicsdir/mask_1.jpg'\n",
    "    # save grayscale image and mask as jpg\n",
    "    cv.imwrite(im, img_gray) \n",
    "    cv.imwrite(label, mask)\n",
    "    \n",
    "  \n",
    "    # extract features\n",
    "    extractor = featureextractor.RadiomicsFeatureExtractor() # create extractor instance from Pyradiomics\n",
    "    result = extractor.execute(im, label) # extract features and save in OrdDict result\n",
    "    values = list(result.values()) # save all values in a list. These values are stored in np.arrays and must be converted to floats \n",
    "    keys = list(result.keys()) # save result keys in a list. These values are stored in np.arrays and must be converted to floats\n",
    "    v = [] # array to store values\n",
    "    k = [] # array to store keys (these will be the column names in the dataframe)\n",
    "    \n",
    "    # iterate through values and append them to list\n",
    "    for i in deepflatten(values[22:]):\n",
    "        v.append(i.tolist())\n",
    "    # iterate through the keys and append them to list\n",
    "    for l in keys[22:]:   \n",
    "        k.append(l)       \n",
    "        \n",
    "    return v, k # return values and keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9b9e198",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to iterate through the images, extract the features and append them to the dataframe\n",
    "\n",
    "def feature_extraction():\n",
    "    \n",
    "    '''\n",
    "    Function that iterates through each image, applies the feature extraction function built previously,\n",
    "    and returns a dataframe with all features.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # columns for rgb features dataframe\n",
    "    columns = ['image_id','red_mode', 'green_mode', 'blue_mode', 'red_median','green_median', 'blue_median', 'red_iqr', 'green_iqr', 'blue_iqr']\n",
    "    \n",
    "    # create dataframe with rgb columns\n",
    "    features_dataframe = pd.DataFrame(columns = columns)\n",
    "    \n",
    "    \n",
    "    # iterate through each image, extract features and append to dataframe\n",
    "    for index, image in enumerate(training_data_csv['image_id']):  \n",
    "        feat_rgb = features_rgb(image)   # extract rgb features with features_rgb function built previously\n",
    "        feat_radio, c = features_radiomics(image)   # extract pyradiomics features with features_radiomics function\n",
    "        col = columns[1:] + c # list with column names for the final dataframe\n",
    "        data = list(deepflatten([feat_rgb, feat_radio])) # data list to append in dataframe\n",
    "        \n",
    "        # append feature data to dataframe. data input as list [], \n",
    "        features_dataframe = features_dataframe.append(pd.DataFrame([data], columns = col, index=[index]));\n",
    "        \n",
    "        \n",
    "        # add data to first column, the image's name\n",
    "        features_dataframe.at[index, columns[0]] = image\n",
    "        \n",
    "        # print progress string: images processed/total images\n",
    "        print(str(index+1) + '/' + str(len(training_data_csv['image_id']))+ ' images processed...')\n",
    "        \n",
    "        # wait for new print to delete old one\n",
    "        clear_output(wait=True)\n",
    "    return features_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6708b687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shape features are only available 3D input (for 2D input, use shape2D). Found 2D input\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 images processed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17638/3018546687.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  features_dataframe = features_dataframe.append(pd.DataFrame([data], columns = col, index=[index]));\n"
     ]
    }
   ],
   "source": [
    "## Hit it! Extract the features \n",
    "## CAUTION: This might take a while\n",
    "all_features = feature_extraction() # call the feature extraction function and let the flames burn\n",
    "\n",
    "# join the training_data dataframe and the features dataframe on the image_id column\n",
    "final_table = training_data_csv.set_index('image_id').join(all_features.set_index('image_id'), how='inner', on='image_id')\n",
    "final_table.to_csv('data.csv') # save final dataframe in a csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaenv",
   "language": "python",
   "name": "aaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
